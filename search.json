[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "This comes from the file data.qmd.\nYour first steps in this project will be to find data to work on.\nI recommend trying to find data that interests you and that you are knowledgeable about. A bad example would be if you have no interest in video games but your data set is about video games. I also recommend finding data that is related to current events, social justice, and other areas that have an impact.\nInitially, you will study one dataset but later you will need to combine that data with another dataset. For this reason, I recommend finding data that has some date and/or location components. These types of data are conducive to interesting visualizations and analysis and you can also combine this data with other data that also has a date or location variable. Data from the census, weather data, economic data, are all relatively easy to combine with other data with time/location components."
  },
  {
    "objectID": "data.html#what-makes-a-good-data-set",
    "href": "data.html#what-makes-a-good-data-set",
    "title": "Data",
    "section": "What makes a good data set?",
    "text": "What makes a good data set?\n\nData you are interested in and care about.\nData where there are a lot of potential questions that you can explore.\nA data set that isn’t completely cleaned already.\nMultiple sources for data that you can combine.\nSome type of time and/or location component."
  },
  {
    "objectID": "data.html#where-to-keep-data",
    "href": "data.html#where-to-keep-data",
    "title": "Data",
    "section": "Where to keep data?",
    "text": "Where to keep data?\nBelow 50mb: In dataset folder\nAbove 50mb: In dataset_ignore folder. This folder will be ignored by git so you’ll have to manually sync these files across your team.\n\nSharing your data\nFor small datasets (&lt;50mb), you can use the dataset folder that is tracked by github. Add the files just like you would any other file.\nIf you create a folder named data this will cause problems.\nFor larger datasets, you’ll need to create a new folder in the project root directory named dataset-ignore. This will be ignored by git (based off the .gitignore file in the project root directory) which will help you avoid issues with Github’s size limits. Your team will have to manually make sure the data files in dataset-ignore are synced across team members.\nYour load_and_clean_data.R file is how you will load and clean your data. Here is a an example of a very simple one.\n\nsource(\n  \"scripts/load_and_clean_data.R\",\n  echo = TRUE # Use echo=FALSE or omit it to avoid code output  \n)\n\n\n&gt; library(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n&gt; loan_data &lt;- read_csv(here::here(\"dataset\", \"loan_refusal.csv\"))\n\n\nRows: 20 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): bank\ndbl (4): min, white, himin, hiwhite\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n&gt; loan_data_clean &lt;- loan_data\n\n&gt; write_csv(loan_data_clean, file = here::here(\"dataset\", \n+     \"loan_refusal_clean.csv\"))\n\n&gt; save(loan_data_clean, file = here::here(\"dataset/loan_refusal.RData\"))\n\n\nYou should never use absolute paths (eg. /Users/danielsussman/path/to/project/ or C:\\MA415\\\\Final_Project\\).\nYou might consider using the here function fomr the here package to avoid path problems.\n\n\nLoad and clean data script\nThe idea behind this file is that someone coming to your website could largely replicate your analyses after running this script on the original data sets to clean them. This file might create a derivative data set that you then use for your subsequent analysis. Note that you don’t need to run this script from every post/page. Instead, you can load in the results of this script, which could be plain text files or .RData files. In your data page you’ll describe how these results were created. If you have a very large data set, you might save smaller data sets that you can use for exploration purposes. To link to this file, you can use [cleaning script](/scripts/load_and_clean_data.R) wich appears as cleaning script."
  },
  {
    "objectID": "data.html#rubric-on-this-page",
    "href": "data.html#rubric-on-this-page",
    "title": "Data",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nDescribe where/how to find data.\n\nYou must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.\nWhy was the data collected/curated? Who put it together? (This is important, if you don’t know why it was collected then that might not be a good dataset to look at.\n\nDescribe the different data files used and what each variable means.\n\nIf you have many variables then only describe the most relevant ones and summarize the rest.\n\nDescribe any cleaning you had to do for your data.\n\nYou must include a link to your load_and_clean_data.R file.\nAlso, describe any additional R packages you used outside of those covered in class.\nDescribe and show code for how you combined multiple data files and any cleaning that was necessary for that.\nSome repetition of what you do in your load_and_clean_data.R file is fine and encouraged if it helps explain what you did.\n\nOrganization, clarity, cleanliness of the page\n\nMake sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.\nThis page should be self-contained."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This comes from the file analysis.qmd.\nWe describe here our detailed data analysis. This page will provide an overview of what questions you hope to ask, illustrations relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You’ll also reflect on next steps and further analysis.\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nprint(getwd())\n\n[1] \"/Users/benzheng/Documents/GitHub/ma-4615-fa23-final-project-team-2\"\n\ndata &lt;- read_csv(here::here(\"dataset/loan_refusal_clean.csv\"))\n\nRows: 20 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): bank\ndbl (4): min, white, himin, hiwhite\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nload(here::here(\"dataset/loan_refusal.RData\"))\nprint(ls())\n\n[1] \"data\"            \"has_annotations\" \"loan_data_clean\""
  },
  {
    "objectID": "analysis.html#note-on-attribution",
    "href": "analysis.html#note-on-attribution",
    "title": "Analysis",
    "section": "Note on Attribution",
    "text": "Note on Attribution\nIn general, you should try to provide links to relevant resources, especially those that helped you. You don’t have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don’t need a formal citation.\nIf you are directly quoting from a source, please make that clear. You can show quotes using &gt; like this\n&gt; To be or not to be.\n\nTo be or not to be."
  },
  {
    "objectID": "analysis.html#rubric-on-this-page",
    "href": "analysis.html#rubric-on-this-page",
    "title": "Analysis",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nIntroduce what motivates your Data Analysis (DA)\n\nWhich variables and relationships are you most interested in?\nWhat questions are you interested in answering?\nProvide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n\nModeling and Inference\n\nThe page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\nExplain the techniques you used for validating your results.\nDescribe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n\nExplain the flaws and limitations of your analysis\n\nAre there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n\nClarity Figures\n\nAre your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\nEach figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\nDefault lm output and plots are typically not acceptable.\n\nClarity of Explanations\n\nHow well do you explain each figure/result?\nDo you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n\nOrganization and cleanliness.\n\nMake sure to remove excessive warnings, use clean easy-to-read code, organize with sections or multiple pages, use bullets, etc.\nThis page should be self-contained."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Blog Post 1\n\n\n3 Datasets\n\n\n\n\n\n\n\n3 datasets we found that could be study\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nBlog post 6\n\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2023\n\n\ngroup 2\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 5\n\n\nCombination of different datasets\n\n\n\n\n\n\n\n\n\nNov 20, 2023\n\n\n\n\n\n\n  \n\n\n\n\nBlog post 4\n\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2023\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 3\n\n\nClean and load data\n\n\n\n\n\n\n\n\n\nNov 7, 2023\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 2\n\n\nData cleanning process\n\n\n\n\n\n\n\nProcess of data loading and cleaning\n\n\n\n\n\n\nOct 30, 2023\n\n\n\n\n\n\n  \n\n\n\n\nGetting started\n\n\n\n\n\n\n\n\n\n\nDirections to set up your website and create your first post.\n\n\n\n\n\n\nOct 15, 2023\n\n\nDaniel Sussman\n\n\n\n\n\n\n  \n\n\n\n\nFirst Team Meeting\n\n\n\n\n\n\n\n\n\n\nThis post details the steps you’ll take for your first team meeting.\n\n\n\n\n\n\nOct 13, 2023\n\n\nDaniel Sussman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-10-23-blog-post-1/blog-post-1.html",
    "href": "posts/2023-10-23-blog-post-1/blog-post-1.html",
    "title": "Blog Post 1",
    "section": "",
    "text": "Dataset 1: Heart Attack Risk Prediction Dataset https://www.kaggle.com/datasets/iamsouravbanerjee/heart-attack-prediction-dataset This dataset, obtained from Kaggle, comprises 26 variables and just over 8000 observations. Its original purpose was to assess the risk of a heart attack, but it also includes variables related to other medical conditions, such as stress level, diabetes, obesity, and more. Using these variables, we can explore various questions, such as identifying the demographic groups most likely to develop specific medical conditions. These demographics include but are not limited to sex, age, and country of origin. While the dataset lacks a specific ethnicity variable, it can be adapted to compare different regions and create ethnic-like categories, enabling comparisons between Latin ethnic groups from Europe and South America, among other possibilities, without making broad assumptions or stereotyping. Dataset 2: Vital Statistics Natality Birth https://www.nber.org/research/data/vital-statistics-natality-birth-data https://data.nber.org/nvss/natality/csv/nat2021us.csv Data 2021 Data on birth rates and demographics is provided by the National Vital Statistics System of the National Center for Health Statistics. This data pertains to births that occurred in a specific calendar year and is derived from information extracted from birth certificates submitted to vital statistics offices in each state and the District of Columbia. The data files for the United States are structured as follows: Prior to 1972, data was based on a 50-percent sample of birth certificates from all states. However, starting in 1972, data transitioned to a 100-percent sample of birth certificates from certain states, while the remaining states continued to provide a 50-percent sample. Over time, the number of states contributing 100 percent of their records has grown, encompassing all states and the District of Columbia by 1985. This dataset comprises a total of 369,928 observations and encompasses 225 factors, which include variables such as the racial background of parents and the health condition of the newborn. Specifically,interested in examining the relationship between a mother’s education, race, and age in this dataset.\nDataset 3 : Proportion adults who are current smokers (2012-2018 California) https://catalog.data.gov/dataset/proportion-of-adults-who-are-current-smokers-lghc-indicator-b50c4 This dataset was originally collected from Let’s Healthy California (https://letsgethealthy.ca.gov/.), an organization dedicated to fostering a collaborative and systematic approach to assess and monitor the health status of Californians. The data within this dataset are amassed monthly, drawing from a random sample of Californians aged 18 and above. Our objective is to delve into the trends and prevalence of smoking among adults in California. Furthermore, we aim to find the interplay between various variables present in the dataset and understand how they influence smoking percentages. author: “” date: “2023-10-23” date-modified: “2023-10-23”"
  },
  {
    "objectID": "posts/2023-11-13-blog-post-4/blog-post-4.html",
    "href": "posts/2023-11-13-blog-post-4/blog-post-4.html",
    "title": "Blog post 4",
    "section": "",
    "text": "Blog post 4 Our dataset: https://www.nber.org/research/data/vital-statistics-natality-birth-data\nAs always, make lots of plots and try different types of plots. However, for this week’s post, only include at most 2 figures/tables/output for your EDA and at most 1 figure/table/output for the modeling. Try to put together figures that illustrate the main lesson’s you’ve learned this week.\nMain Variables As mentioned previously, the main goal of our analysis is to observe the factors that influence a child’s weight at birth. Hence, our response variable comes naturally as “dbwt” or the birth weight in grams. We decided to observe the impact of numerous predictor variables on the birth weight, including:\n“mager”: Mother’s age of pregnancy “cig_before” (our variable): A variable we created that observes mothers who’ve smoked before pregnancy (“cig_0”), but not during(0 values for cig_1,cig_2, and cig_3) “cig_during” (our variable): A variable we created that observes mothers who’ve smoked during pregnancy (positive values in cig_1, cig_2, cig_3, cig_0) “cig_none” (our variable): A variable we created that observes whether or not the mother smoked at all “rf_gdiab”: Gestational diabetes “previs”: Number of prenatal visits “meduc”: Mother’s education in years “bmi”: Mother’s BMI\nColumn Transformations We have transformed the cig_0 (daily number of cigarettes before pregnancy), cig_1 (daily number of cigarettes during 1st trimester), cig_2 (daily number of cigarettes during 2nd trimester), and cig_3 (daily number of cigarettes during 3rd trimester) variables, to create two new dummy variables: “cig_before”, “cig_during”, and “cig_none”. These dummy variables would show whether or not smoking only before, during, or none at all affect the weight of the infant.\nLinear Modeling for First child birth age\nResidual standard error: 4.402 on 99990 degrees of freedom Multiple R-squared: 0.412, Adjusted R-squared: 0.412 F-statistic: 7785 on 9 and 99990 DF, p-value: &lt; 2.2e-16\nIn the linear regression analysis conducted, the dependent variable was the maternal age at first child’s birth (mager), modeled as a function of various maternal characteristics and health-related behaviors. The independent variables in the model included maternal education (meduc), height (m_ht_in), Body Mass Index (BMI), pre-pregnancy weight (pwgt_r), weight at delivery (dwgt_r), marital status (Married), presence of gestational diabetes (GDiabetes), and smoking habits before and during pregnancy (cig_before and cig_during, respectively). The results revealed that each of these factors had a statistically significant impact on the age at which a woman has her first child. Notably, maternal education emerged as a particularly influential factor, with the analysis indicating that each additional unit of education was associated with an increase of approximately 1.6 years in the age at first birth, controlling for other factors. This finding aligns with existing literature that suggests higher education levels often correlate with delayed childbearing. Other significant predictors included marital status and gestational diabetes, with married women and those with gestational diabetes having their first child at an older age. The model’s adjusted R-squared value was 0.412, indicating that approximately 41.2% of the variance in maternal age at first birth could be explained by the included predictors. This substantial proportion underscores the importance of these factors in understanding patterns of maternal age at first birth. The statistical significance of the model was confirmed with an F-statistic of 7785 on 9 and 99990 degrees of freedom, and a p-value of less than 2.2e-16, reinforcing the model’s robustness and the reliability of its predictions.\nModeling for Baby weight\nResidual standard error: 582.1 on 99989 degrees of freedom Multiple R-squared: 0.04285, Adjusted R-squared: 0.04276 F-statistic: 447.7 on 10 and 99989 DF, p-value: &lt; 2.2e-16\nIn this linear regression model, the dependent variable is the baby’s birth weight (dbwt), examined in relation to a set of maternal factors similar to those considered in the previous analysis. The independent variables encompass maternal age at first birth (mager), education level (meduc), height (m_ht_in), BMI, pre-pregnancy weight (pwgt_r), delivery weight (dwgt_r), marital status (Married), gestational diabetes (GDiabetes), and smoking habits before and during pregnancy (cig_before and cig_during). The model’s findings reveal that these factors are statistically significant predictors of birth weight, albeit with varying degrees of impact.Notably, maternal height and marital status were positively associated with higher birth weights, with each unit increase in height resulting in an 18.73-gram increase in birth weight. Conversely, smoking during pregnancy (cig_during) had a substantial negative impact, with each unit increase in this variable associated with a 387.74-gram decrease in birth weight, highlighting the significant adverse effects of smoking during pregnancy on fetal development. The effect of maternal age was negative, indicating a slight decrease in birth weight as maternal age increased.\nHowever, the overall explanatory power of this model, as indicated by the adjusted R-squared value (0.04276), suggests that only about 4.28% of the variability in birth weight is accounted for by these variables. This is significantly lower compared to the previous model predicting maternal age at first birth, where approximately 41.2% of the variance was explained. This difference might reflect the complex and multifaceted nature of factors influencing birth weight, many of which could be outside the scope of the variables considered in this model. The model’s statistical significance is affirmed by an F-statistic of 447.7 on 10 and 99989 degrees of freedom, with a p-value of less than 2.2e-16. Despite its statistical significance, the relatively low adjusted R-squared value underlines the necessity of considering additional or different factors to better understand and predict birth weight variations.\nDiagram of Birth Age vs Prepreg Education Level  The “First Kid Birth Age vs Prepreg Education Level” plot graphically delineates the correlation between maternal age at the birth of the first child and the education level prior to pregnancy, with race as a categorical variable. The depicted trends across all racial groups suggest a positive association between educational attainment and the age at which a woman has her first child. This consistency in trend indicates that higher education levels are potentially correlated with delayed childbearing, a phenomenon supported by demographic studies linking educational pursuits to later maternity. The variations in trend slopes across different races may imply underlying socio-economic and cultural factors influencing reproductive decisions. The confidence intervals, while providing a measure of estimate reliability, indicate less precision at the extremes of education levels, reflecting the inherent variability and potentially lower data density at these points.\nDiagram of Birthweight vs First Kid Birth Age  The plot visualizes the association between the birth weight of a child and the maternal age at the time of the first child’s birth, with race as a differentiating variable. The data suggests a non-linear relationship; for most racial groups, there is an initial increase in birth weight with maternal age, followed by a subsequent decline after a certain age threshold. The inference drawn from these trends could indicate a peak age range for optimal birth weight outcomes, which may vary by race. This peak likely reflects a complex interplay of biological and socio-economic factors, including health status and access to prenatal care. The width of the confidence intervals indicates varying degrees of certainty in the predictions, particularly at younger and older maternal ages, suggesting a need for cautious interpretation in these ranges. This pattern reiterates the significance of age as a factor in neonatal health."
  },
  {
    "objectID": "posts/2023-10-15-getting-started/getting-started.html",
    "href": "posts/2023-10-15-getting-started/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "Below, the items marked with [[OP]] should only be done by one person on the team.\n\nTo get started\n\n[[OP]] One person from the team should click the Github Classroom link on Teams.\n[[OP]] That person types in the group name for their group.\nThe rest of the team now clicks the Github Classroom link and selects their team from the dropdown list.\nFinally, each of you can clone the repository to your laptop like a normal assignment.\n\n\n\nSetting up the site\n\n[[OP]] Open the terminal and run quarto publish gh-pages.\n[[OP]] Select Yes to the prompt:  ? Publish site to https://sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME/ using gh-pages? (Y/n)\n[[OP]] Wait for the process to finish.\nOnce it is done, you can go to the URL it asked you about to see your site.\n\nNote: This is the process you will use every time you want to update your published site. Make sure to always follow the steps below for rendering, previewing, and committing your changes before doing these publish steps. Anyone can publish in the future.\n\n\nCustomize your site\n\n[[OP]] Open the _quarto.yml file and update the title to include your team name.\n[[OP]] Go to the about.qmd and remove the TF’s and professor’s names.\nadd your own along with a short introduction and a link to your Github user page.\n[[OP]] Render the site.\n[[OP]] Check and make sure you didn’t get any errors.\n[[OP]] Commit your changes and push.\n[[OP]] Repeat the steps under Setting up your site.\n\nOnce one person is done with this, each teammate in the group can, in turn, repeat steps 3-7. Before doing so, make sure to pull the changes from teammates before starting to make new changes. (We’ll talk soon about ways to organize your work and resolve conflicts.)\n\n\nStart your first post\n\nTo start your first post first, run remotes::install_github(\"sussmanbu/quartopost\") in your Console.\n[[OP]] Run quartopost::quartopost() (or click Addins-&gt;Create Quarto Post, or use C-Shift-P, type “Create Quarto” and press enter to run the command).\n\nNow you can start working on your post.\nEvery time you want to make a new post, you can repeat step 2 above. When you want to publish your progress, follow steps 4-7 from Customize your site.\nFinally, make sure to read through everything on this site which has the directions and rubric for the final project."
  },
  {
    "objectID": "posts/2023-11-07-blog-post-3/blog-post-3.html",
    "href": "posts/2023-11-07-blog-post-3/blog-post-3.html",
    "title": "Blog Post 3",
    "section": "",
    "text": "Our dataset: https://www.nber.org/research/data/vital-statistics-natality-birth-data This dataset contains a total of 3,669,928 observations with 225 different factors.The dataset is a valuable resource interested in understanding how maternal education, racial backgrounds, and maternal age impact various aspects of childbirth, healthcare, and demographic trends in the United States. It plays a critical role in addressing disparities and improving healthcare and support systems for expectant mothers and newborns\nData Cleaning: Can eliminate the following variables: Mother’s age, race, education, daily smoke before pregnancy, height in inches, bmi, weight in pound before pregnancy, weight in pound when delivered, gestational diabetes, Birth Weight\nOur focus: We are trying to use variables to make inference on the age at which a woman is pregnant. We also might combine data from both parents, variables determine the child’s health or even the child’s weight. We are trying to discover the variable and effect on women’s maternity situations.\nData for Equity Principle 1: Transparency For this principle, we will provide clear documentation on the process of how the data collected, cleaned, processed, and analyzed. To disclose transformations happening within the data and the rationale of what we based on. Principle 2: Privacy and Confidentiality Protect the privacy and confidentiality of individuals by ensuring that personally identifiable information is protected.Respecting individual privacy is essential for ethical data analysis and maintaining trust in the data collection process.\nLimitations We have a large dataset with 3,669,928 observations, This may cause overfitting. To fix this problem, we currently plan to build a model with samples with partial data. Secondly, there may exist selection bias on the variable. In the dataset, there are 225 different factors. We might be influenced by our perception of choosing/cleaning the dataset, which might bring in some bias. To overcome this problem, we would examine the variable carefully and minimize the chance of this type of bias.\nPotential for abuse or misuse The dataset contains comprehensive information of each recordent, there exists potential privacy breach. Besides, they might contain Bias in Treatment. As the dataset contains the information about the economic status and geographic region information, the revelations may give rise to biased behaviors."
  },
  {
    "objectID": "posts/2023-11-20-blog-post-5/blog-post-5.html",
    "href": "posts/2023-11-20-blog-post-5/blog-post-5.html",
    "title": "Blog Post 5",
    "section": "",
    "text": "To explore and understand mother marnterl data, we try to combining datasets for a more comprehensive analysis.\nWe choose Real Per Capita Personal Income data—from 2016 to 2021. In our ongoing journey to explore and understand complex economic trends, we’ve embarked on an ambitious project: combining multiple datasets for a more comprehensive analysis. We delve into the integration of a Real Per Capita Personal Income data—from 2016 to 2021 dataset.\nThe process involves meticulously combining our original dataset with additional data, encompassing a range of CDC provided birth related variables from 2014 to 2021. These variables include the number of births, birth rate per 1,000 population, fertility rate per 1,000 women aged 15-44, percentages of births categorized as low birthweight and preterm, the percentage of unmarried mothers, and the mean age at first birth.\nWe’re still in the process of refining our analysis with new struture. There might need further data cleaning, exploring potential correlations, and following our past idea with our final project."
  },
  {
    "objectID": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "href": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "title": "First Team Meeting",
    "section": "",
    "text": "These are the steps that you will take today to get started on your project. Today, you will just be brainstorming, and then next week, you’ll get started on the main aspects of the project.\n\nStart by introducing yourselves to each other. I also recommend creating a private channel on Microsoft Teams with all your team members. This will be a place that you can communicate and share ideas, code, problems, etc.\nDiscuss what aspects of the project each of you are more or less excited about. These include\n\nCollecting, cleaning, and munging data ,\nStatistical Modeling,\nVisualization,\nWriting about analyses, and\nManaging and reviewing team work.\n\nBased on this, discuss where you feel your strengths and weaknesses might be.\nNext, start brainstorming questions you hope to answer as part of this project. This question should in some way be addressing issues around racial disparities. The questions you come up with should be at the level of the question we started with when exploring the HMDA data. (“Are there differences in the ease of securing a loan based on the race of the applicant?”) You’ll revise your questions a lot over the course of the project. Come up with a few questions that your group might be interested in exploring.\nBased on these questions, start looking around for data that might help you analyze this. If you are looking at U.S. based data, data.gov is a good source and if you are looking internationally, I recommend checking out the World Bank. Also, try Googling for data. Include “data set” or “dataset” in your query. You might even include “CSV” or some other format. Using “data” by itself in your query often doesn’t work too well. Spend some time searching for data and try to come up with at least three possible data sets. (Next week, you’ll write short proposals about each of them that I’ll give feedback on.)\nCome up with a team name. Next week, I’ll provide the Github Classroom assignment that will be where you work on your final project and you’ll have to have your team name finalized by then. Your project will be hosted online at the website with a URL like sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME.\n\nNext week, you’ll get your final project website set up and write your first blog post."
  },
  {
    "objectID": "posts/2023-11-30-blog-post-6/blog-post-6.html",
    "href": "posts/2023-11-30-blog-post-6/blog-post-6.html",
    "title": "Blog post 6",
    "section": "",
    "text": "In the exploratory data analysis phase of our research, we meticulously selected a subset of 20,000 data points from each year spanning 2016 to 2021, from the extensive Vital Statistics Natality Birth Data. This strategic selection has allowed for a manageable yet representative dataset, enabling us to perform a more focused and detailed analysis. Our EDA process involves a multifaceted approach focused on the tendency of women first pregnant age and correlation, employing advanced statistical techniques to dissect and understand the nuances within the data. The aim here is to explore underlying trends, distributions, and potential relationships among key variables such as maternal age, education, race, and health conditions. By methodically visualizing and analyzing these yearly datasets, we aim to uncover evolving patterns and insights that could shed light on the factors influencing birth outcomes over these years.\nAfter careful consideration and preliminary analysis, our research has crystallized around a pivotal thesis focused on underage pregnancy. The thesis posits that “Underage pregnancy is intricately linked to a spectrum of socio-economic, educational, and health-related factors, and these relationships have evolved distinctly over the years from 2016 to 2021.” This thesis is not a mere hypothesis but a guiding statement that shapes our research direction. It implies a complex interplay of various factors influencing underage pregnancy, with an emphasis on how these dynamics have changed over recent years. The goal of our research is to delve into these aspects, using our rich dataset to substantiate or refine our thesis, thereby contributing meaningful insights into the discourse on underage pregnancy.\nIn the final stages of our research, significant emphasis is being placed on refining our visualizations and tables. Recognizing the crucial role of clear and compelling visuals in conveying complex data, we are employing tools like ggpubr for graph enhancements and the gt package for sophisticated table formatting. These tools not only aid in the aesthetic enhancement of our figures and tables but also ensure that they effectively communicate the nuances and findings of our analysis. Each visualization is carefully crafted to highlight key trends and insights, with special attention to detail in titles, captions, annotations, and highlights. This approach not only aids in the clarity of our presentation but also serves to reinforce and illustrate the primary findings and implications of our research, particularly in relation to our thesis on underage pregnancy. &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n\n—\n\n\n\n\n\n\n\nfb8980d84d52a88d4476b23d16ed12658cb02e9f"
  },
  {
    "objectID": "posts/2023-10-30-blog-post-2-/blog-post-2-.html",
    "href": "posts/2023-10-30-blog-post-2-/blog-post-2-.html",
    "title": "Blog Post 2",
    "section": "",
    "text": "Dataset 1 Job Note for future: use broom::tidy() to represent regression statistics\nhttps://data.boston.gov/dataset/boston-jobs-policy-compliance-reports/resource/5ab4b4de-c970-4619-ab55-ce4338535b24\nThis is the link to the original data set which has 412,931 observations with 14 different variables. It describes the type of employees that were hired for various development projects taking place in Boston. We can use this dataset to outline the relationships between the area of residence, ethnicity, sex, and job someone may have. The goal of this dataset was to offer insights into how project managers and individual development initiatives adhere to policy requirements, as determined by their workforce. By gathering and sharing data related to the Residents Jobs Policy, the City aims to diminish disparities related to race and gender in construction projects while simultaneously enhancing employment prospects for Boston residents.\nThis dataset is not one of our original 3 datasets that we included in blog post 1. We felt that our original 3 proposed datasets were not adequate enough to conduct our project in. The first dataset was from Kaggle and generated by chatGPT so any outcomes that we would have come to throughout our project would not be based on real data. The second dataset was not only massive, but also the variables were mainly describing the demographics of a mother, a father, and their child so there wasn’t much opportunity to make a significant predictive model. The third dataset was simply too small. We feel that this dataset is definitely big enough and gives us opportunities to predict various outcomes. For example, we could potentially predict the demographics of workers based on where the development project takes place.\nOriginal 14 variables: agency, compliance_project_name, project_address, neighborhood, developer, general_contractor_name, subcontractor, trade, period_ending, gender, person_of_color, race, boston_resident, worker_hours_this_period\nData Cleaning:\nCan eliminate the following variables: person_of_color, project_address, developer, general_contractor_name, subcontractor\nperson_of_color: this is a binary variable but can look at “race” to determine whether the person is of color or not, so this variable is not necessary. project_address: There is a “neighborhood” variable that is a little more general but still encapsulates the residence of the particular observation. A specific address may be too small and trivial to actually be predicted, or be used to predict.\nDataset 2 Birth data: https://www.nber.org/research/data/vital-statistics-natality-birth-data This dataset contains a total of 3,669,928 observations with 225 different factors. It provides comprehensive information about births that occurred in the United States, based on data extracted from birth certificates submitted to vital statistics offices in each state. The dataset spans multiple years, with data collection methods evolving over time.\nThe dataset is a valuable resource interested in understanding how maternal education, racial backgrounds, and maternal age impact various aspects of childbirth, healthcare, and demographic trends in the United States. It plays a critical role in addressing disparities and improving healthcare and support systems for expectant mothers and newborns\nData Cleaning:\nCan eliminate the following variables: Mother’s age,race, education, daily smoke before pregnancy, height in inches, bmi, weight in pound before pregnancy, weight in pound when delivered, pre-diabetes, Birth Weight"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Team TEAMNAME. The members of this team are below."
  },
  {
    "objectID": "about.html#chang-liu",
    "href": "about.html#chang-liu",
    "title": "About",
    "section": "Chang Liu",
    "text": "Chang Liu\nLuis is a Ph.D. student in Stats and is the Teaching Fellow for the course."
  },
  {
    "objectID": "about.html#dan-sussman",
    "href": "about.html#dan-sussman",
    "title": "About",
    "section": "Dan Sussman",
    "text": "Dan Sussman\nDan is a professor in the Math/Stat department and is the instructor for the course."
  },
  {
    "objectID": "about.html#shiying-wu",
    "href": "about.html#shiying-wu",
    "title": "About",
    "section": "Shiying Wu",
    "text": "Shiying Wu\nSenior student major in Statistics. Prefer name is Angel."
  },
  {
    "objectID": "about.html#hao-yu",
    "href": "about.html#hao-yu",
    "title": "About",
    "section": "Hao Yu",
    "text": "Hao Yu\nQuestrom’24, concentration in Business Analytic."
  },
  {
    "objectID": "about.html#angelo-orciuoli",
    "href": "about.html#angelo-orciuoli",
    "title": "About",
    "section": "Angelo Orciuoli",
    "text": "Angelo Orciuoli\nAngelo is a 4th year studying Data Science and Mathematics."
  },
  {
    "objectID": "about.html#jesse-jungwon-choi",
    "href": "about.html#jesse-jungwon-choi",
    "title": "About",
    "section": "Jesse Jungwon Choi",
    "text": "Jesse Jungwon Choi\nJesse is a 2nd year studying Data Sciecne and Economics."
  },
  {
    "objectID": "about.html#jiabin-zheng",
    "href": "about.html#jiabin-zheng",
    "title": "About",
    "section": "Jiabin Zheng",
    "text": "Jiabin Zheng\nJiabin is a 4th year studying Mathematics and Statistics.\n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Big Picture",
    "section": "",
    "text": "This comes from the file big_picture.Rmd.\nThink of this page as your 538/Upshot style article. This means that you should try to tell a story through the data and your analysis. Read articles from those sites and similar sites to get a feeling for what they are like. Importantly, these should be geared towards the general public. You shouldn’t assume the reader understands how to interpret a linear regression. Focus on interpretation and visualizations."
  },
  {
    "objectID": "big_picture.html#rubric-on-this-page",
    "href": "big_picture.html#rubric-on-this-page",
    "title": "Big Picture",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nTitle\n\nYour big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.\n\nClarity of Explanation\n\nYou should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don’t go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.\nEach figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.\n\nCreativity\n\nDo your best to make things interesting. Think of a story. Think of how each part of your analysis supports the previous part or provides a different perspective.\n\nThis page should be self-contained.\n\nNote: This page should have no code visible, i.e. use #| echo: FALSE."
  },
  {
    "objectID": "big_picture.html#rubric-other-components",
    "href": "big_picture.html#rubric-other-components",
    "title": "Big Picture",
    "section": "Rubric: Other components",
    "text": "Rubric: Other components\n\nInteractive\nYou will also be required to make an interactive dashboard like this one.\nYour Big Data page should include a link to an interactive dashboard. The dashboard should be created either using Shiny or FlexDashboard (or another tool with professor’s approval). This interactive component should in some way support your thesis from your big picture page. Good interactives often provide both high-level understanding of the data while allowing a user to investigate specific scenarios, observations, subgroups, etc.\n\nQuality and ease of use of the interactive components. Is it clear what can be explored using your interactive components? Does it enhance and reinforce your conclusions from the Big Picture? Plotly with default hover text will get no credit. Be creative!\n\n\n\nVideo Recording\nMake a video recording (probably using Zoom) demonstrating your interactive components. You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA. This video should be no longer than 4 minutes. Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website. This can be presented by any subset of the team members.\n\n\nRest of the Site\nFinally, here are important things to keep in mind for the rest of the site.\nThe main title of your page is informative. Each post has an author/description/informative title. All lab required posts are present. Each page (including the home page) has a nice featured image associated with it. Your about page is up to date and clean. You have removed the generic posts from the initial site template."
  }
]